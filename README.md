Welcome to my journey through the wild world of ETL pipelines! ðŸš€

So, picture this: I stumbled upon this treasure trove of data on Kaggle, packed with insights about teams and players from various sports leagues. While I've dabbled in predictive modeling with Prophet and regression techniques on this data, I thought, "Why not take it up a notch and build a slick ETL pipeline from scratch?"

And thus, the adventure began. ðŸ’¼

First stop: extracting data. I got my hands on this nifty code snippet here](https://gist.github.com/Christymacarena/399c40828e1041d0188ac103a8c19564). Trust me, it's worth its weight in gold!

Next, I ventured into the realm of setting up the perfect environment. Out with Windows, in with Linux! After installing Linux and diving headfirst into the vast ocean of Apache Airflow documentation, I even indulged in not one, but TWO LinkedIn Learning video courses. ðŸ¤“

Fast forward three days of relentless Googling and futile attempts to coerce the webserver to run on Windows (spoiler alert: it's a lost cause), I cracked the code! Airflow now gracefully glides through my Ubuntu setup like a seasoned pro.

And that, my friend, is how I tamed the ETL beast, one line of code at a time. ðŸ’»âœ¨

Stay tuned for more tales from the data trenches!
